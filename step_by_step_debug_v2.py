#!/usr/bin/env python3
"""
é€æ­¥è°ƒè¯• - è·Ÿè¸ªç®—æ³•æ¯ä¸ªæ­¥éª¤çš„è¾“å‡º
å¸¦å¯è§†åŒ–åŠŸèƒ½ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œåˆ†æ
"""

import numpy as np
import laspy
import sys
import os

sys.path.insert(0, '.')

from corridor_seg.config import Config
from corridor_seg.preprocessing import PointCloudPreprocessor
from corridor_seg.features import FeatureCalculator
from corridor_seg.powerlines import PowerLineExtractor
from corridor_seg.towers import TowerExtractor
from visualization import PowerGridVisualizer

def step_by_step_debug(enable_visualization=True, save_dir="debug_visualizations"):
    """é€æ­¥æ‰§è¡Œç®—æ³•å¹¶æ£€æŸ¥æ¯æ­¥è¾“å‡º
    
    Args:
        enable_visualization: æ˜¯å¦å¯ç”¨å¯è§†åŒ–
        save_dir: å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•
    """
    
    print("=== é€æ­¥è°ƒè¯•æ¨¡å¼ï¼ˆå¸¦å¯è§†åŒ–ï¼‰===")
    
    # åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
    visualizer = None
    if enable_visualization:
        visualizer = PowerGridVisualizer(save_dir)
        print(f"ğŸ“Š å¯è§†åŒ–ç»“æœå°†ä¿å­˜åˆ°: {save_dir}")
    
    # ç”¨äºæ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats = {}
    
    # 1. åŠ è½½å°æ ·æœ¬æ•°æ®
    input_file = "/home/lambdayin/Code-Projects/maicro-projects/detection/3d/Spatil-Line-Clustering/data/cloud4db26d1a9662f7ae_Block_0.las"
    las = laspy.read(input_file)
    sample_points = np.vstack([las.x, las.y, las.z]).T
    
    # å–ä¸€ä¸ªè¾ƒå°çš„æ ·æœ¬è¿›è¡Œè°ƒè¯•
    # sample_size = 500000  # 50ä¸‡ç‚¹
    # indices = np.random.choice(len(points), sample_size, replace=False)
    # sample_points = points[indices]
    
    print(f"ä½¿ç”¨æ ·æœ¬: {len(sample_points):,} ç‚¹")
    print(f"é«˜åº¦èŒƒå›´: {sample_points[:, 2].min():.2f} - {sample_points[:, 2].max():.2f}m")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['original_points'] = len(sample_points)
    stats['height_range'] = f"{sample_points[:, 2].min():.2f} - {sample_points[:, 2].max():.2f}m"
    
    # å¯è§†åŒ–åŸå§‹ç‚¹äº‘
    if visualizer:
        visualizer.visualize_original_pointcloud(
            sample_points, 
            title="Step 1: Original Point Cloud"
        )
    
    # 2. ä½¿ç”¨æå®½æ¾çš„é…ç½®
    # config = Config()
    # config.grid_2d_size = 5.0
    # config.voxel_size = 0.5
    # config.min_height_gap = 10.0     # æä½
    # config.a1d_linear_thr = 0.6      # é™ä½
    # config.collinearity_angle_thr = 20.0  # å¢å¤§

    config = Config("./examples/custom_config.yaml")
    
    print(f"é…ç½®å‚æ•°:")
    print(f"  min_height_gap: {config.min_height_gap}m")
    print(f"  a1d_linear_thr: {config.a1d_linear_thr}")
    
    # 3. Step 1: é¢„å¤„ç†
    print("\\n=== Step 1: é¢„å¤„ç† ===")
    preprocessor = PointCloudPreprocessor(config)
    preprocessed = preprocessor.preprocess(sample_points)
    
    filtered_points = preprocessed['points']
    grid_2d = preprocessed['grid_2d']
    voxel_hash_3d = preprocessed['voxel_hash_3d']
    delta_h_min = preprocessed['delta_h_min']
    tower_head_height = preprocessed['tower_head_height']
    # åŸç‚¹ï¼ˆä¸é¢„å¤„ç†ä¸€è‡´ï¼‰
    bounds = preprocessed.get('bounds', {})
    min_coords = bounds.get('min_coords', None)
    grid_origin = None
    voxel_origin = None
    if min_coords is not None and len(min_coords) >= 3:
        grid_origin = (float(min_coords[0]), float(min_coords[1]))
        voxel_origin = (float(min_coords[0]), float(min_coords[1]), float(min_coords[2]))
    
    print(f"âœ… è¿‡æ»¤åç‚¹æ•°: {len(filtered_points):,}")
    print(f"âœ… 2Dç½‘æ ¼æ•°: {len(grid_2d)}")
    print(f"âœ… 3Dä½“ç´ æ•°: {len(voxel_hash_3d)}")
    print(f"âœ… Î”h_min: {delta_h_min:.2f}m")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['filtered_points'] = len(filtered_points)
    stats['removal_rate'] = (len(sample_points) - len(filtered_points)) / len(sample_points) * 100
    stats['grid_2d_count'] = len(grid_2d)
    stats['voxel_3d_count'] = len(voxel_hash_3d)
    stats['delta_h_min'] = delta_h_min
    stats['voxel_size'] = config.voxel_size
    
    # å¯è§†åŒ–é¢„å¤„ç†ç»“æœ
    if visualizer:
        visualizer.visualize_preprocessed_points(
            sample_points, filtered_points, delta_h_min,
            title="Step 2: Preprocessing Results"
        )
        
        # å¯è§†åŒ–ä½“ç´ ç½‘æ ¼
        visualizer.visualize_voxel_grid(
            voxel_hash_3d, grid_2d, filtered_points, config,
            title="Step 3: Voxel Grid Structure",
            grid_origin=grid_origin,
            voxel_origin=voxel_origin
        )
    
    # 4. Step 2: ç‰¹å¾è®¡ç®—
    print("\\n=== Step 2: ç‰¹å¾è®¡ç®— ===")
    feature_calc = FeatureCalculator(config)
    
    # è®¡ç®—ä½“ç´ ç‰¹å¾
    voxel_features = feature_calc.compute_voxel_features(voxel_hash_3d, filtered_points)
    print(f"âœ… ä½“ç´ ç‰¹å¾: {len(voxel_features)}")
    
    # è¯†åˆ«çº¿æ€§ç»“æ„
    linear_voxels = feature_calc.identify_linear_structures(voxel_features)
    print(f"âœ… çº¿æ€§ä½“ç´ : {len(linear_voxels)}")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['linear_voxels'] = len(linear_voxels)
    stats['a1d_threshold'] = config.a1d_linear_thr
    stats['linear_ratio'] = len(linear_voxels) / len(voxel_features) * 100 if voxel_features else 0
    
    if len(linear_voxels) == 0:
        print("âŒ é—®é¢˜ï¼šæ²¡æœ‰è¯†åˆ«åˆ°çº¿æ€§ç»“æ„ï¼")
        
        # åˆ†æä¸ºä»€ä¹ˆæ²¡æœ‰çº¿æ€§ç»“æ„
        a1d_values = [f['a1D'] for f in voxel_features.values()]
        print(f"   æ‰€æœ‰ä½“ç´ çš„a1Dåˆ†å¸ƒ:")
        print(f"   å¹³å‡: {np.mean(a1d_values):.3f}")
        print(f"   æœ€å¤§: {np.max(a1d_values):.3f}")
        print(f"   >0.3çš„æ¯”ä¾‹: {np.sum(np.array(a1d_values) > 0.3)/len(a1d_values)*100:.1f}%")
        print(f"   >0.6çš„æ¯”ä¾‹: {np.sum(np.array(a1d_values) > 0.6)/len(a1d_values)*100:.1f}%")
        
        # æ‰‹åŠ¨è®¾ç½®æ›´ä½çš„é˜ˆå€¼
        print("   å°è¯•æ›´ä½çš„é˜ˆå€¼...")
        for threshold in [0.5, 0.4, 0.3, 0.2, 0.1]:
            count = np.sum(np.array(a1d_values) > threshold)
            print(f"   a1D > {threshold}: {count} ä½“ç´ ")
            if count > 0:
                config.a1d_linear_thr = threshold
                linear_voxels = feature_calc.identify_linear_structures(voxel_features)
                print(f"   âœ… ä½¿ç”¨é˜ˆå€¼{threshold}ï¼Œè¯†åˆ«åˆ°{len(linear_voxels)}ä¸ªçº¿æ€§ä½“ç´ ")
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                stats['linear_voxels'] = len(linear_voxels)
                stats['a1d_threshold'] = threshold
                stats['linear_ratio'] = len(linear_voxels) / len(voxel_features) * 100
                break
    
    if len(linear_voxels) == 0:
        print("âŒ ä»ç„¶æ²¡æœ‰çº¿æ€§ç»“æ„ï¼Œé€€å‡ºè°ƒè¯•")
        return
    
    # 5. Step 3: æ£€æŸ¥çº¿æ€§ä½“ç´ çš„é«˜åº¦åˆ†å¸ƒ
    print("\\n=== Step 3: çº¿æ€§ä½“ç´ åˆ†æ ===")
    linear_heights = []
    for features in linear_voxels.values():
        if 'centroid' in features:
            linear_heights.append(features['centroid'][2])
    
    print(f"çº¿æ€§ä½“ç´ é«˜åº¦èŒƒå›´: {min(linear_heights):.2f} - {max(linear_heights):.2f}m")
    print(f"å¹³å‡é«˜åº¦: {np.mean(linear_heights):.2f}m")
    
    # é«˜åº¦è¿‡æ»¤æ£€æŸ¥
    above_threshold = [h for h in linear_heights if h > delta_h_min]
    print(f"é«˜äºÎ”h_min({delta_h_min:.2f}m)çš„çº¿æ€§ä½“ç´ : {len(above_threshold)}")
    
    if len(above_threshold) == 0:
        print("âŒ é—®é¢˜ï¼šæ‰€æœ‰çº¿æ€§ä½“ç´ éƒ½è¢«é«˜åº¦é˜ˆå€¼è¿‡æ»¤æ‰äº†ï¼")
        print(f"   å»ºè®®å°†Î”h_miné™ä½åˆ°: {min(linear_heights) - 1:.2f}m")
        
        # å³ä½¿æœ‰é—®é¢˜ä¹Ÿè¦å¯è§†åŒ–ï¼Œå¸®åŠ©è°ƒè¯•
        if visualizer:
            visualizer.visualize_linear_voxels(
                linear_voxels, voxel_features, voxel_hash_3d, config, delta_h_min,
                title="Step 4: Linear Voxel Analysis (PROBLEMATIC)"
            )
        return
    
    # å¯è§†åŒ–çº¿æ€§ä½“ç´ åˆ†æ
    if visualizer:
        visualizer.visualize_linear_voxels(
            linear_voxels, voxel_features, voxel_hash_3d, config, delta_h_min,
            title="Step 4: Linear Voxel Analysis"
        )
    
    # 6. Step 4: ç”µåŠ›çº¿æå–
    print("\\n=== Step 4: ç”µåŠ›çº¿æå– ===")
    powerline_extractor = PowerLineExtractor(config)
    
    # æå–å±€éƒ¨æ®µ
    segments = powerline_extractor.extract_local_segments(
        linear_voxels, voxel_features, filtered_points, delta_h_min)
    
    print(f"âœ… å±€éƒ¨æ®µæ•°: {len(segments)}")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['segments'] = len(segments)
    
    if len(segments) == 0:
        print("âŒ é—®é¢˜ï¼šæ²¡æœ‰æå–åˆ°å±€éƒ¨æ®µï¼")
        return
    
    # å¯è§†åŒ–ç”µåŠ›çº¿æ®µ
    if visualizer:
        visualizer.visualize_power_line_segments(
            segments, filtered_points,
            title="Step 5: Power Line Segments"
        )
    
    # åˆ†ææ®µçš„ç‰¹å¾
    segment_lengths = [seg.get('length', 0) for seg in segments]
    print(f"æ®µé•¿åº¦èŒƒå›´: {min(segment_lengths):.2f} - {max(segment_lengths):.2f}m")
    print(f"å¹³å‡æ®µé•¿åº¦: {np.mean(segment_lengths):.2f}m")
    
    # æ„å»ºå…¼å®¹æ€§å›¾
    graph = powerline_extractor.build_segment_graph(segments, grid_2d, grid_origin=grid_origin)
    print(f"âœ… å…¼å®¹æ€§å›¾: {graph.number_of_nodes()} èŠ‚ç‚¹, {graph.number_of_edges()} è¾¹")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['graph_nodes'] = graph.number_of_nodes()
    stats['graph_edges'] = graph.number_of_edges()
    
    # å…¨å±€åˆå¹¶
    power_lines = powerline_extractor.merge_segments_global(graph, segments)
    print(f"âœ… åˆå¹¶åç”µåŠ›çº¿: {len(power_lines)}")
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['raw_powerlines'] = len(power_lines)
    
    if len(power_lines) > 0:
        for i, pl in enumerate(power_lines):
            print(f"  ç”µåŠ›çº¿ {i}: é•¿åº¦={pl.get('total_length', 0):.2f}m, "
                  f"æ®µæ•°={pl.get('num_segments', 0)}, ç‚¹æ•°={len(pl.get('point_indices', []))}")
    
    # è¿‡æ»¤
    filtered_lines = powerline_extractor.filter_power_lines(power_lines, min_length=10.0, min_segments=1)
    print(f"âœ… è¿‡æ»¤åç”µåŠ›çº¿: {len(filtered_lines)}")

    pl_mask = np.zeros(len(filtered_points), dtype=bool)
    for pl in power_lines:
        pl_mask[pl['point_indices']] = True
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    stats['final_powerlines'] = len(filtered_lines)
    if filtered_lines:
        total_length = sum(pl.get('total_length', 0) for pl in filtered_lines)
        stats['total_length'] = total_length
        
        # è®¡ç®—ç‚¹æ•°ç»Ÿè®¡
        stats['linear_points'] = sum(len(lv.get('point_indices', [])) for lv in linear_voxels.values() if 'point_indices' in lv)
        stats['segment_points'] = sum(len(seg.get('point_indices', [])) for seg in segments)
        stats['final_points'] = sum(len(pl.get('point_indices', [])) for pl in filtered_lines)
    else:
        stats['total_length'] = 0
        stats['linear_points'] = 0
        stats['segment_points'] = 0
        stats['final_points'] = 0
    
    # 7. Tower Detection Pipeline
    print("\\n=== Step 5: å¡”æ£€æµ‹æµç¨‹ ===")
    tower_extractor = TowerExtractor(config)
    
    # ä¼°ç®—å¡”å¤´é«˜åº¦ï¼ˆåŸºäºç”µåŠ›çº¿é«˜åº¦ï¼‰
    # if filtered_lines:
    #     line_heights = []
    #     for pl in filtered_lines:
    #         if 'point_indices' in pl and len(pl['point_indices']) > 0:
    #             pl_points = filtered_points[pl['point_indices']]
    #             line_heights.extend(pl_points[:, 2])
        
    #     if line_heights:
    #         # å¡”å¤´é«˜åº¦ä¼°ç®—ä¸ºç”µåŠ›çº¿é«˜åº¦çš„95%åˆ†ä½æ•°
    #         tower_head_height = np.percentile(line_heights, 95)
    #         print(f"  åŸºäºç”µåŠ›çº¿é«˜åº¦ä¼°ç®—å¡”å¤´é«˜åº¦: {tower_head_height:.2f}m")
    #     else:
    #         tower_head_height = 15.0  # é»˜è®¤å€¼
    #         print("  ä½¿ç”¨é»˜è®¤å¡”å¤´é«˜åº¦: 15.0m")
    # else:
    #     tower_head_height = 15.0
    #     print("  ä½¿ç”¨é»˜è®¤å¡”å¤´é«˜åº¦: 15.0m")

    # éœ€è¦å…ˆè®¡ç®—ç½‘æ ¼ç‰¹å¾ï¼ˆåŒ…å«HeightDiffï¼‰
    print("\\n=== Step 5.0: è®¡ç®—ç½‘æ ¼ç‰¹å¾ï¼ˆç”¨äºå¡”æ£€æµ‹ï¼‰===")
    
    # grid_features = {}
    
    # for grid_idx, point_indices in grid_2d.items():
    #     if not point_indices:
    #         continue
            
    #     grid_points = filtered_points[point_indices]
    #     heights = grid_points[:, 2]
        
    #     # è®¡ç®—ç½‘æ ¼ç‰¹å¾
    #     features = {
    #         'point_count': len(point_indices),
    #         'centroid': grid_points.mean(axis=0),
    #         'HeightDiff': heights.max() - heights.min(),
    #         'max_height': heights.max(),
    #         'min_height': heights.min(),
    #         'density': len(point_indices) / (config.grid_2d_size ** 2)
    #     }
    #     grid_features[grid_idx] = features

    grid_features = feature_calc.compute_2d_grid_features(
            grid_2d, filtered_points, pl_candidate_mask=pl_mask)
    grid_features = feature_calc.compute_height_based_features(
            grid_features, delta_h_min, tower_head_height)

    print(f"âœ… è®¡ç®—ç½‘æ ¼ç‰¹å¾: {len(grid_features)} ä¸ªç½‘æ ¼")
    stats['grid_features'] = len(grid_features)
    
    # Step 5.1: åˆå§‹é«˜åº¦å·®ç­›é€‰
    candidates_step1 = tower_extractor.step1_height_diff_initial_screening(
        grid_features, delta_h_min, tower_head_height)
    
    print(f"âœ… å¡”æ£€æµ‹æ­¥éª¤1: {len(candidates_step1)} ä¸ªå€™é€‰ç½‘æ ¼")
    stats['tower_step1_candidates'] = len(candidates_step1)
    
    # å¯è§†åŒ–å¡”æ£€æµ‹æ­¥éª¤1
    if visualizer and candidates_step1:
        visualizer.visualize_tower_step1_initial_screening(
            candidates_step1, grid_features, delta_h_min, tower_head_height,
            title="Tower Step 1: Initial Height Screening"
        )
    
    if not candidates_step1:
        print("âŒ å¡”æ£€æµ‹æ­¥éª¤1å¤±è´¥ï¼šæ²¡æœ‰å€™é€‰ç½‘æ ¼")
        stats.update({
            'tower_step2_candidates': 0,
            'tower_step3_candidates': 0,
            'tower_clusters': 0,
            'final_towers': 0,
            'tower_points': 0
        })
    else:
        # Step 5.2: ç§»åŠ¨çª—å£ç»†åŒ–
        candidates_step2 = tower_extractor.step2_moving_window_refinement(
            grid_features, candidates_step1, tower_head_height, delta_h_min)
        
        print(f"âœ… å¡”æ£€æµ‹æ­¥éª¤2: {len(candidates_step2)} ä¸ªå€™é€‰ç½‘æ ¼")
        stats['tower_step2_candidates'] = len(candidates_step2)
        
        # å¯è§†åŒ–å¡”æ£€æµ‹æ­¥éª¤2
        if visualizer and candidates_step2:
            visualizer.visualize_tower_step2_window_refinement(
                candidates_step1, candidates_step2, grid_features, tower_head_height,
                title="Tower Step 2: Moving Window Refinement"
            )
        
        if not candidates_step2:
            print("âŒ å¡”æ£€æµ‹æ­¥éª¤2å¤±è´¥ï¼šæ²¡æœ‰å€™é€‰ç½‘æ ¼")
            stats.update({
                'tower_step3_candidates': 0,
                'tower_clusters': 0,
                'final_towers': 0,
                'tower_points': 0
            })
        else:
            # Step 5.3: å‚ç›´è¿ç»­æ€§æ£€æŸ¥
            candidates_step3 = tower_extractor.step3_vertical_continuity_check(
                candidates_step2, grid_features, filtered_points, tower_head_height,
                grid_2d=grid_2d, grid_origin=grid_origin)
            
            print(f"âœ… å¡”æ£€æµ‹æ­¥éª¤3: {len(candidates_step3)} ä¸ªå€™é€‰ç½‘æ ¼")
            stats['tower_step3_candidates'] = len(candidates_step3)
            
            # å¯è§†åŒ–å¡”æ£€æµ‹æ­¥éª¤3
            if visualizer and candidates_step3:
                visualizer.visualize_tower_step3_vertical_continuity(
                    candidates_step2, candidates_step3, grid_features, 
                    filtered_points, tower_head_height,
                    title="Tower Step 3: Vertical Continuity Check"
                )
            
            if not candidates_step3:
                print("âŒ å¡”æ£€æµ‹æ­¥éª¤3å¤±è´¥ï¼šæ²¡æœ‰å€™é€‰ç½‘æ ¼")
                stats.update({
                    'tower_clusters': 0,
                    'final_towers': 0,
                    'tower_points': 0
                })
            else:
                # Step 5.4: èšç±»æˆå¡”
                tower_clusters = tower_extractor.step4_clustering_to_towers(
                    candidates_step3, grid_features)
                
                print(f"âœ… å¡”æ£€æµ‹æ­¥éª¤4: {len(tower_clusters)} ä¸ªå¡”èšç±»")
                stats['tower_clusters'] = len(tower_clusters)
                
                # å¯è§†åŒ–å¡”æ£€æµ‹æ­¥éª¤4
                if visualizer and tower_clusters:
                    visualizer.visualize_tower_step4_clustering(
                        candidates_step3, tower_clusters, grid_features,
                        title="Tower Step 4: Clustering to Towers"
                    )
                
                if not tower_clusters:
                    print("âŒ å¡”æ£€æµ‹æ­¥éª¤4å¤±è´¥ï¼šæ²¡æœ‰å¡”èšç±»")
                    stats.update({
                        'final_towers': 0,
                        'tower_points': 0
                    })
                else:
                    # Step 5.5: å¹³é¢åŠå¾„çº¦æŸ
                    final_towers = tower_extractor.step5_planar_radius_constraint(
                        tower_clusters, filtered_points, grid_2d=grid_2d, grid_origin=grid_origin)
                                 
                    print(f"âœ… å¡”æ£€æµ‹æ­¥éª¤5: {len(final_towers)} ä¸ªæœ€ç»ˆå¡”")
                    stats['final_towers'] = len(final_towers)
                    
                    # è®¡ç®—å¡”çš„ç‚¹æ•°ç»Ÿè®¡
                    tower_points = sum(len(t.get('points', [])) for t in final_towers)
                    stats['tower_points'] = tower_points
                    
                    # å¯è§†åŒ–å¡”æ£€æµ‹æ­¥éª¤5å’Œæœ€ç»ˆç»“æœ
                    if visualizer:
                        visualizer.visualize_tower_step5_radius_constraint(
                            tower_clusters, final_towers, filtered_points,
                            title="Tower Step 5: Final Tower Results"
                        )
                    
                    if final_towers:
                        for i, tower in enumerate(final_towers):
                            points_count = len(tower.get('points', []))
                            radius = tower.get('radius', 0)
                            height_diff = tower.get('max_height_diff', 0)
                            print(f"  å¡” {i}: ç‚¹æ•°={points_count}, åŠå¾„={radius:.2f}m, é«˜åº¦å·®={height_diff:.2f}m")
                    
                    # å¯è§†åŒ–å®Œæ•´çš„ç”µåŠ›ç½‘æ ¼ç³»ç»Ÿ
                    if visualizer and (filtered_lines or final_towers):
                        visualizer.visualize_complete_power_grid_system(
                            filtered_lines, final_towers, filtered_points,
                            title="Complete Power Grid System (Lines + Towers)"
                        )
    
    # å¯è§†åŒ–ç”µåŠ›çº¿æœ€ç»ˆç»“æœ
    if visualizer:
        visualizer.visualize_final_results(
            power_lines, filtered_lines, filtered_points,
            title="Step 4: Final Power Line Results"
        )
        
        # åˆ›å»ºæ€»ç»“æŠ¥å‘Š
        visualizer.create_summary_report(stats)
    
    print("\\n=== è°ƒè¯•å®Œæˆ ===")
    final_towers_count = stats.get('final_towers', 0)
    print(f"æœ€ç»ˆç»“æœ: {len(filtered_lines)} æ¡ç”µåŠ›çº¿ + {final_towers_count} ä¸ªå¡”")
    
    if visualizer:
        print(f"\\nğŸ“Š æ‰€æœ‰å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {visualizer.save_dir}")
        print("   åŒ…å«ä»¥ä¸‹æ–‡ä»¶:")
        print("   â€¢ 00_summary_report.png - ç®—æ³•æ‰§è¡Œæ€»ç»“")
        print("   â€¢ 01_original_pointcloud.png - åŸå§‹ç‚¹äº‘")
        print("   â€¢ 02_preprocessing_results.png - é¢„å¤„ç†ç»“æœ")
        print("   â€¢ 03_voxel_grid.png - ä½“ç´ ç½‘æ ¼ç»“æ„")
        print("   â€¢ 04_linear_voxels.png - çº¿æ€§ä½“ç´ åˆ†æ")
        print("   â€¢ 05_power_line_segments.png - ç”µåŠ›çº¿æ®µ")
        print("   â€¢ 06_final_results.png - ç”µåŠ›çº¿æœ€ç»ˆç»“æœ")
        if stats.get('tower_step1_candidates', 0) > 0:
            print("   â€¢ 07_tower_step1_screening.png - å¡”æ£€æµ‹æ­¥éª¤1")
            print("   â€¢ 08_tower_step2_refinement.png - å¡”æ£€æµ‹æ­¥éª¤2")
            print("   â€¢ 09_tower_step3_continuity.png - å¡”æ£€æµ‹æ­¥éª¤3")
            print("   â€¢ 10_tower_step4_clustering.png - å¡”æ£€æµ‹æ­¥éª¤4")
            print("   â€¢ 11_tower_step5_final.png - å¡”æ£€æµ‹æœ€ç»ˆç»“æœ")
            print("   â€¢ 12_complete_system.png - å®Œæ•´ç”µåŠ›ç½‘æ ¼ç³»ç»Ÿ")
    
    return stats

if __name__ == "__main__":
    np.random.seed(42)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='PowerGridç®—æ³•é€æ­¥è°ƒè¯•å·¥å…·')
    parser.add_argument('--no-vis', action='store_true', help='ç¦ç”¨å¯è§†åŒ–')
    parser.add_argument('--save-dir', default='debug_visualizations', help='å¯è§†åŒ–ä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    enable_visualization = not args.no_vis
    
    stats = step_by_step_debug(enable_visualization, args.save_dir)
    
    print("\\n" + "="*50)
    print("ğŸ“‹ è°ƒè¯•ä¼šè¯ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"   {key}: {value}")
    print("="*50)